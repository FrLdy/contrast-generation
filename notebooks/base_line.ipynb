{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "e134e05457d34029b6460cd73bbf1ed73f339b5b6d98c95be70b69eba114fe95"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as torch_data\n",
    "from torchsummary import summary\n",
    "from torchvision import models\n",
    "from pycocotools.coco import COCO\n",
    "import torchvision.transforms as transforms\n",
    "import json\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import os, sys\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "from models.base_line.model import BaseLine\n",
    "from models.autoencoders.components import ConvBlock\n",
    "from models.GANs.model import ConstrastDCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyDataset(torch_data.Dataset):\n",
    "    def __init__(self, len=64):\n",
    "        super().__init__()\n",
    "        self.len = len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.ones(3, 128, 128), torch.ones(3, 128, 128)*2, torch.zeros(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_train_dl    = torch_data.DataLoader(torch.ones(8, 3, 128, 128), batch_size=4)\n",
    "disc_train_dl   = torch_data.DataLoader(torch.ones(50, 3, 64, 64), batch_size=4)\n",
    "ae_train_dl     = torch_data.DataLoader(ToyDataset(8), batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = BaseLine(\n",
    "    512*2*2, 512,\n",
    "    ae_train_dl=ae_train_dl,\n",
    "    disc_train_dl=disc_train_dl,\n",
    "    gen_train_dl=gen_train_dl\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name               | Type           | Params\n",
      "------------------------------------------------------\n",
      "0 | ae                 | ResUnetAE      | 72.8 M\n",
      "1 | conv_input_decoder | ConvBlock      | 75.5 M\n",
      "2 | bridge_union       | Sequential     | 47.2 M\n",
      "3 | gan                | ConstrastDCGAN | 30.7 M\n",
      "------------------------------------------------------\n",
      "226 M     Trainable params\n",
      "0         Non-trainable params\n",
      "226 M     Total params\n",
      "904.730   Total estimated model params size (MB)\n",
      "Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s] "
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(reload_dataloaders_every_epoch=True, max_epochs=2)\n",
    "trainer.fit(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}