{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "from torchsummary import summary\n",
    "from torchvision import models\n",
    "import pytorch_lightning as pl\n",
    "import wandb\n",
    "\n",
    "import os, sys\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from models.autoencoders.ae import ResUnetAE\n",
    "from models.autoencoders.components import UpBlock\n",
    "\n",
    "from datasets.coco.datasets import CocoDataLoader\n",
    "from datasets.coco.dataloaders import singles_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=99.28s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "cocoDataLoader = CocoDataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = singles_dataloader(\n",
    "    cocoDataLoader.singles_dataset(slice(0, 12)),\n",
    "    2/3, 4, True, 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = next(iter(dataloaders[\"train\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[tensor([[[[ 0.0505,  0.1276,  0.0441,  ..., -0.1892, -0.4696, -0.1849],\n",
       "           [-0.0073,  0.0098,  0.1297,  ..., -0.3048, -0.3455, -0.3412],\n",
       "           [ 0.1147,  0.0291,  0.1854,  ..., -0.3755, -0.2641, -0.0779],\n",
       "           ...,\n",
       "           [ 0.3673,  0.4637,  0.9496,  ...,  0.8918,  0.7826,  0.7184],\n",
       "           [ 0.6649,  0.9431,  1.1465,  ..., -0.2235,  0.0313,  0.9196],\n",
       "           [ 0.8618,  0.9260,  0.6370,  ...,  0.7719,  0.7505,  0.2004]],\n",
       " \n",
       "          [[ 0.2599,  0.4109,  0.1045,  ..., -0.0749, -0.2872, -0.1690],\n",
       "           [ 0.0367,  0.0783,  0.2074,  ..., -0.2084, -0.3069, -0.1078],\n",
       "           [ 0.2293,  0.3080,  0.1767,  ..., -0.1318, -0.2062,  0.0192],\n",
       "           ...,\n",
       "           [ 0.6057,  0.8704,  1.2228,  ...,  1.1878,  1.0696,  0.9821],\n",
       "           [ 0.8792,  1.2250,  1.3672,  ...,  0.2139,  0.3474,  1.1243],\n",
       "           [ 1.0871,  1.1856,  0.8858,  ...,  1.0827,  1.0018,  0.6166]],\n",
       " \n",
       "          [[-0.4341, -0.4842, -0.4711,  ..., -0.5278, -0.4166, -0.5038],\n",
       "           [-0.4406, -0.3164, -0.4929,  ..., -0.6258, -0.8219, -0.6171],\n",
       "           [-0.3513, -0.1182, -0.2380,  ..., -0.6258, -0.5147, -0.2227],\n",
       "           ...,\n",
       "           [ 1.2086,  1.4308,  1.9276,  ...,  1.7380,  1.6879,  1.5332],\n",
       "           [ 1.5332,  1.8993,  2.0104,  ...,  0.8884,  0.9189,  1.7359],\n",
       "           [ 1.7206,  1.7228,  1.5572,  ...,  1.6836,  1.5420,  1.1956]]],\n",
       " \n",
       " \n",
       "         [[[ 0.3529,  0.2530,  0.2875,  ..., -0.3843, -0.5303, -0.1222],\n",
       "           [ 0.2875,  0.1986,  0.2624,  ..., -1.0851, -0.6879, -0.4937],\n",
       "           [ 0.2530,  0.2195,  0.2240,  ..., -0.6931, -0.8487, -0.6256],\n",
       "           ...,\n",
       "           [ 1.5066,  1.5356,  1.6453,  ...,  1.3343,  1.5237,  1.1973],\n",
       "           [ 1.4533,  1.4500,  1.4157,  ...,  1.5697,  1.2649,  1.4987],\n",
       "           [ 1.7244,  1.6357,  1.7540,  ...,  1.2774,  1.4737,  1.3900]],\n",
       " \n",
       "          [[ 0.9611,  0.9914,  0.9102,  ...,  0.2315,  0.0791,  0.2223],\n",
       "           [ 0.9930,  0.9883,  0.9769,  ..., -0.1066,  0.1386,  0.1486],\n",
       "           [ 0.9773,  0.9615,  0.9798,  ...,  0.0222, -0.0206,  0.0486],\n",
       "           ...,\n",
       "           [ 1.8430,  1.9191,  1.9262,  ...,  2.0206,  1.9655,  1.9995],\n",
       "           [ 1.7586,  1.7169,  1.7788,  ...,  1.9687,  2.0051,  2.0293],\n",
       "           [ 1.9608,  1.9146,  1.9464,  ...,  1.7855,  1.8699,  1.6441]],\n",
       " \n",
       "          [[ 1.8224,  1.8809,  2.0760,  ...,  1.1561,  1.1154,  1.2278],\n",
       "           [ 1.8858,  1.8336,  1.9622,  ...,  1.1237,  1.1465,  1.1793],\n",
       "           [ 1.8959,  1.9734,  1.8706,  ...,  1.1542,  1.0443,  1.2143],\n",
       "           ...,\n",
       "           [ 1.9464,  2.0343,  2.0413,  ...,  1.9393,  2.0335,  1.9994],\n",
       "           [ 1.9160,  1.8966,  1.9093,  ...,  1.9603,  2.0125,  2.1111],\n",
       "           [ 1.9381,  2.0554,  2.0221,  ...,  1.8081,  1.9285,  1.8369]]],\n",
       " \n",
       " \n",
       "         [[[-0.3751, -0.2776, -0.1999,  ...,  1.0070,  0.7031,  1.0720],\n",
       "           [-0.2964, -0.2267, -0.1125,  ...,  0.7736,  1.3849,  1.5723],\n",
       "           [ 0.4293,  0.0230, -0.4166,  ...,  1.4364,  1.0960,  0.9902],\n",
       "           ...,\n",
       "           [ 0.7112,  0.6360,  0.6425,  ...,  1.0794,  0.9814,  0.9372],\n",
       "           [ 0.8312,  1.0875,  1.0945,  ...,  1.1050,  1.1585,  0.7293],\n",
       "           [ 1.1385,  1.1101,  1.0135,  ...,  0.9811,  0.5510,  0.6811]],\n",
       " \n",
       "          [[-0.5258, -0.4284, -0.4051,  ...,  1.0914,  0.7738,  1.0900],\n",
       "           [-0.3672, -0.3129, -0.2150,  ...,  0.9011,  1.3386,  1.5348],\n",
       "           [ 0.4210, -0.0032, -0.4488,  ...,  1.4841,  1.1082,  0.9460],\n",
       "           ...,\n",
       "           [ 0.4641,  0.4776,  0.5331,  ...,  0.8724,  0.7062,  0.5890],\n",
       "           [ 0.6291,  0.8911,  0.8728,  ...,  0.9138,  0.9600,  0.5541],\n",
       "           [ 0.9109,  0.9267,  0.7862,  ...,  0.6572,  0.1225,  0.2492]],\n",
       " \n",
       "          [[-0.3607, -0.2560, -0.1575,  ...,  1.2637,  0.9179,  1.2521],\n",
       "           [-0.1627, -0.1057, -0.0811,  ...,  1.0921,  1.5316,  1.7124],\n",
       "           [ 0.5950,  0.1748, -0.2722,  ...,  1.6561,  1.3225,  1.1492],\n",
       "           ...,\n",
       "           [ 0.1870,  0.1299,  0.1393,  ...,  0.5202,  0.3923,  0.2787],\n",
       "           [ 0.2142,  0.4718,  0.5230,  ...,  0.5885,  0.6007,  0.1194],\n",
       "           [ 0.5659,  0.5448,  0.3601,  ...,  0.4051, -0.1278, -0.0661]]],\n",
       " \n",
       " \n",
       "         [[[-2.1179, -2.0865, -2.1037,  ..., -2.0324, -1.5328, -1.5417],\n",
       "           [-2.0837, -2.0752, -2.0405,  ..., -1.5524, -1.6209, -2.0059],\n",
       "           [-1.9741, -1.9597, -1.8316,  ..., -0.9582, -1.4500, -1.6905],\n",
       "           ...,\n",
       "           [-2.1035, -2.1035, -2.1179,  ..., -2.1179, -2.1008, -2.1035],\n",
       "           [-2.0837, -2.0923, -2.1094,  ..., -2.0923, -2.1179, -2.1094],\n",
       "           [-2.1150, -2.0950, -2.1008,  ..., -2.1037, -2.1150, -2.0979]],\n",
       " \n",
       "          [[-0.4543, -0.4601, -0.6936,  ..., -0.6556, -0.6353, -0.7431],\n",
       "           [-0.6181, -0.3814, -0.6262,  ..., -0.5384, -0.5304, -0.9332],\n",
       "           [-0.8186, -0.4685, -0.6414,  ..., -0.2297, -0.6821, -0.8299],\n",
       "           ...,\n",
       "           [-1.5658, -1.4958, -1.5280,  ..., -1.8950, -1.9776, -1.9188],\n",
       "           [-1.5543, -1.5454, -1.5193,  ..., -2.0095, -1.8783, -1.9395],\n",
       "           [-1.6476, -1.6097, -1.5455,  ..., -1.9190, -1.8577, -1.9803]],\n",
       " \n",
       "          [[-0.9766, -0.9447, -1.7319,  ..., -0.7732, -0.4973, -0.7559],\n",
       "           [-1.0554, -1.0288, -1.8044,  ..., -0.2959, -0.3666, -0.9851],\n",
       "           [-1.1937, -1.1665, -1.4796,  ...,  0.4125, -0.4129, -0.6988],\n",
       "           ...,\n",
       "           [-0.4422, -0.2156, -0.3230,  ..., -1.6413, -1.7584, -1.7577],\n",
       "           [-0.4100, -0.2096, -0.2795,  ..., -1.7608, -1.7259, -1.7784],\n",
       "           [-0.5640, -0.4740, -0.3927,  ..., -1.7232, -1.7667, -1.7667]]]]),\n",
       " ('sports', 'sports', 'sports', 'sports')]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bridge_out_channels = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = ResUnetAE(\n",
    "    resnet,\n",
    "    bridge_out_channels,\n",
    "    UpBlock.UPSAMPLING_BILINEAR,\n",
    "    (128, 128), \n",
    "    lr=0.02\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 4, 4])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "autoencoder(torch.rand(1, 3, 232, 232)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:101: UserWarning: you defined a validation_step but have no val_dataloader. Skipping val loop\n",
      "  rank_zero_warn(f'you defined a {step_name} but have no {loader_name}. Skipping {stage} loop')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to `offline` in this directory.  Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.\n",
      "\n",
      "  | Name    | Type          | Params\n",
      "------------------------------------------\n",
      "0 | encoder | ResnetEncoder | 11.2 M\n",
      "1 | maxpool | MaxPool2d     | 0     \n",
      "2 | bridge  | Bridge        | 14.2 M\n",
      "3 | decoder | UnetDecoder   | 10.2 M\n",
      "------------------------------------------\n",
      "35.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "35.6 M    Total params\n",
      "142.228   Total estimated model params size (MB)\n",
      "Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s] /usr/local/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:102: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Epoch 4: 100%|██████████| 2/2 [00:12<00:00,  6.30s/it, loss=0.555, v_num=rcj5, train_loss=0.368]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 17296<br/>Program ended successfully."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find user logs for this run at: <code>/Users/francoisledoyen/Documents/FAC/GENERATION_TEXTE_IMAGES/code/contrast-generation/notebooks/wandb/offline-run-20210628_151629-k6earcj5/logs/debug.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find internal logs for this run at: <code>/Users/francoisledoyen/Documents/FAC/GENERATION_TEXTE_IMAGES/code/contrast-generation/notebooks/wandb/offline-run-20210628_151629-k6earcj5/logs/debug-internal.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mwandb sync /Users/francoisledoyen/Documents/FAC/GENERATION_TEXTE_IMAGES/code/contrast-generation/notebooks/wandb/offline-run-20210628_151629-k6earcj5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "wandb.login()\n",
    "wandb_logger = pl.loggers.WandbLogger()\n",
    "trainer = pl.Trainer(logger=wandb_logger, max_epochs=5)\n",
    "trainer.fit(autoencoder, dataloaders[\"train\"])\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e134e05457d34029b6460cd73bbf1ed73f339b5b6d98c95be70b69eba114fe95"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}